[{"num": 1, "sprints": [{"id": 1, "start": "07.01.2020", "end": "21.01.2020", "text": "<h2 class='report_headline'>First Report and overview</h2><br><p class='report_paragraph'>The first thing I wanted to accomplish was to put up a shell for the blog. Having recently taught myself React and Typescript, this was a great opportunity to try it out. The backend is extremely simple, and for now it is just a node server using express js. The idea as of now is just to fetch the entire dataset, and pass the necessary props down, but if more complexity is added it might be a good idea to only fetch the contents of the reports that are requested. I might also want to implement more CRUD-operations in the future. I am a bit unsure how much code I should put up here, as my entire project cannot be open source for obvious reasons. I will have to be a bit restrictive anyhow.</p><br><p class='report_paragraph'>The next thing I did was to implement a python parser that goes through a text that has been marked up with an extremely simple markup language, and creates a report from it. So far it only deals with headlines and texts, so that will have to be improved later.</p><br><p class='report_paragraph'>I also hope to complete a little bit of styling to make it look a bit nicer.</p><br><h4 class='report_subheader'>Notes and pointers</h4><br><p class='report_paragraph'>Reading the first few research articles was enlightening. A lot of things make a lot of sense, other things don't. The overarching question of how to improve dialogue systems is such a complex and loaded one that has to be modularized to make sense. Making a bit more sense of the question, one can ask, what makes a dialogue system good? Unfortunately, that question is unanswerable to almost the same degree as the previous one. Context has to be applied for any form of measurement to make sense. If humans were completely rational beings who all hold the same goals and ideas, it could be simple. One can for example measure how many questions a dialogue system can process, understand, and make an action towards answering. However, a user might misinterpret the answer that the system has provided, which renders the action practically useless in that certain setting, even though the system performed the correct action for general use.</p><br><p class='report_paragraph'>If one uses a more rational approach however, and rather ask the question 'how does my system perform, and how does that performance differ from how I want it to work?', it is much easier to evaluate. Though it does not make it easier to solve, as a dialogue system is built from different modules. For example, there has to be a part of the system with the responsibility of understanding what the user is saying. Then the system has to break that down into something measurable, in order to evaluate what it can do about it. Now this system is an entirely different beast on its own, there has to be a way to track the state of the conversation, there has to be a way of knowing which actions are available to the system at any given point, and a way to evaluate which action is most suitable to move to a different state that makes the most sense for the situation. Finally, there are infinitely many ways of responding to the utterance of the user. Some are obviously more suitable than others, and that entirely depends on the situation.</p><br><p class='report_paragraph'>In other words, context matters. One cannot expect a system to be able to respond to everything, or even reasonably to utterances clearly outside of the scope of the context. The context is extremely important. Therefore, I will completely ignore it for now. It does not have the theoretical importance before a few other things are properly laid out and understood.</p><br><h4 class='report_subheader'>Weak supervision</h4><br><p class='report_paragraph'>For natural language processing, machine learning is extremely useful for building models. There are many ways of creating models using machine learning approaches, however there are a few that stand out. First of all, supervised learning makes the most sense for building a model that is to be used for semantic extraction. If we can tell the model which examples of the data we've got are right and which ones are wrong for what we are looking for, it can obviously learn quicker tha if we let it figure it out by itself. Within supervised machine learning methods deep learning is leading the competition to be 'state of the art'.</p><br><p class='report_paragraph'>Deep learning is extremely effective for semantic analysis. There are problems connected to it though, most of them practical. Given infinite data, infinite computing power, and infinite time, deep learning is unbeatable. Those things are however almost never a given. We often have a lot of data for a given context, but we rarely have enough labelled data. We need to tell a supervised learning algorithm which examples should be classified in some way, and which should be classified in another. Generally, this is done through the so-called gold standard labels, where by hand each element in a data set is labeled. This takes a lot of time, and for some contexts, it can be very expensive.</p><br><p class='report_paragraph'>There have been several attempts to solve this in recent years. Williams et al. (2015) proposes the paradigm of interactive learning, where a domain expert can label the elements of a certain perplexity and propagating to similar elements, spending a fraction of the time it requires to hand label a dataset. While clever, there are some issues with the approach. If more data is added in the future of simlar context but with differently structured content, the propogation might have some issues. It seems that a lot of problems could be solved with a scalable, at least semi-automatic labelling process with minimal need for continuous domain expertise.</p><br><p class='report_paragraph'>Weak supervision is a relatively new paradigm that seeks to solve this problem of lack of domain knowledge, by approaching the problem in a different way. What if, instead of operating from a ground truth, one could write functions to automatically label the data? That would be pretty neat. This is of course not as accurate as hand labeling, but it is a lot cheaper in all measurable ways. It obviously requires some heuristic knowledge of the data, in order to create these functions, but it makes the process scalable in a whole other way. The evaluation of the elements differ slightly from evaluation by hand, as there will be cases where a function either cannot decide on a label if the heuristic rules are not sufficient. There will also be disagreements between the functions, which will affect the level of noise. We can then use the information about these disagreements to learn dependencies between the different functions, as to which functions fixes or reinforces others.</p><br>"}]}]